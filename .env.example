# AI-Prepper Docker Configuration
# Copy this to .env and adjust as needed

# Ollama Configuration
OLLAMA_DATA_PATH=./data/ollama
OLLAMA_MODELS=llama3.2,nomic-embed-text

# ChromaDB Configuration  
CHROMA_DATA_PATH=./data/chroma
CHROMA_COLLECTION=wikipedia

# Flowise Configuration
FLOWISE_DATA_PATH=./data/flowise
FLOWISE_USERNAME=admin
FLOWISE_PASSWORD=changeme

# Wikipedia Configuration
WIKIPEDIA_DATA_PATH=./data/wikipedia
WIKIPEDIA_LANGUAGE=en
MAX_ARTICLES=10000

# Processing Configuration
CHUNK_SIZE=512
CHUNK_OVERLAP=128
BATCH_SIZE=100

# Model Configuration
LLM_MODEL=llama3.2
EMBEDDING_MODEL=nomic-embed-text
TEMPERATURE=0.7
MAX_TOKENS=2048

# External Drive Configuration (if using)
# Uncomment and set to your external drive path
# EXTERNAL_DRIVE_PATH=/Volumes/MyDrive/ai-prepper-data
# OLLAMA_DATA_PATH=${EXTERNAL_DRIVE_PATH}/ollama
# CHROMA_DATA_PATH=${EXTERNAL_DRIVE_PATH}/chroma
# FLOWISE_DATA_PATH=${EXTERNAL_DRIVE_PATH}/flowise
# WIKIPEDIA_DATA_PATH=${EXTERNAL_DRIVE_PATH}/wikipedia